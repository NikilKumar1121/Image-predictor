{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input,decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 993s 2us/step\n"
     ]
    }
   ],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image1.jpg\n",
      "[[('n03680355', 'Loafer', 0.99374384), ('n03047690', 'clog', 0.0047027296), ('n04133789', 'sandal', 0.00071248313)]]\n",
      "\n",
      "image2.jpg\n",
      "[[('n03793489', 'mouse', 0.12542786), ('n02992529', 'cellular_telephone', 0.100494355), ('n02951585', 'can_opener', 0.08722105)]]\n",
      "\n",
      "image3.jpg\n",
      "[[('n02403003', 'ox', 0.9996088), ('n02389026', 'sorrel', 0.00016668798), ('n02412080', 'ram', 8.8595225e-05)]]\n",
      "\n",
      "image4.jpg\n",
      "[[('n02992529', 'cellular_telephone', 0.32904664), ('n04074963', 'remote_control', 0.30168825), ('n04356056', 'sunglasses', 0.09844727)]]\n",
      "\n",
      "image5.jpg\n",
      "[[('n02708093', 'analog_clock', 0.64350206), ('n04548280', 'wall_clock', 0.3564971), ('n02794156', 'barometer', 2.796126e-07)]]\n",
      "\n",
      "image6.jpg\n",
      "[[('n03792782', 'mountain_bike', 0.7016491), ('n02835271', 'bicycle-built-for-two', 0.08555681), ('n04482393', 'tricycle', 0.07235032)]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('images'):\n",
    "    print(file)\n",
    "    full_path =\"images/\" + file\n",
    "    \n",
    "    image=load_img(full_path,target_size=(224,224))\n",
    "    image=img_to_array(image)\n",
    "    image= image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n",
    "    image=preprocess_input(image)\n",
    "    y_pred=model.predict(image)\n",
    "    label=decode_predictions(y_pred,top=3)\n",
    "    print(label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
